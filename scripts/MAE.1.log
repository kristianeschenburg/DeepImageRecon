nohup: ignoring input
/mnt/home/keschenb/anaconda2/lib/python2.7/site-packages/dicom/__init__.py:53: UserWarning: 
This code is using an older version of pydicom, which is no longer 
maintained as of Jan 2017.  You can access the new pydicom features and API 
by installing `pydicom` from PyPI.
See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org 
for more information.

  warnings.warn(msg)
/mnt/home/keschenb/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
data_save
{'modelname': '.epochs.20.batch.1.cost.MAE.', 'outputdir': '../checkpoints/MAE/'}
data_load
{'noise': 'AX_Flair_Clear.nii.gz', 'input_directory': '../data/', 'by_slice': True, 'truth': 'T2_Flair_Sense.nii.gz'}
model
{'num_poolings': 3, 'lr_init': 0.001, 'batch_size': 1, 'epochs': 20, 'validation_split': 0.1, 'loss_function': 'mean_absolute_error', 'num_conv_per_pooling': 3, 'batch_norm': True}
process 2 data description
will augment data with 8 augmentations
Noise image: ../data/subj_2/AX_Flair_Clear.nii.gz
Ground truth image: ../data/subj_2/T2_Flair_Sense.nii.gz
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Noise image: ../data/subj_1/AX_Flair_Clear.nii.gz
Ground truth image: ../data/subj_1/T2_Flair_Sense.nii.gz
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
Image loaded, data size (1, 560, 560, 1) (sample, x, y, channel)
mean, min, max
(0.01846921154887226, 0.0, 0.18957323827149758)
(0.01731801098172829, 0.0, 0.3111756534601273)
(-0.0011512005671439362, -0.16804906380624643, 0.2666311220629995)
generate train dataset with augmentation size (480, 560, 560, 1),(480, 560, 560, 1)
Traceback (most recent call last):
  File "script_demo_train.py", line 135, in <module>
    modelfile = ''.join([modelparams['modeldir'],'model_demo.',modelparams['modelname'],'.json'])
KeyError: 'modeldir'
